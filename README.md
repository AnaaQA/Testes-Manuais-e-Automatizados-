[![Typing SVG](https://readme-typing-svg.herokuapp.com/?color=000000&size=35&center=true&vCenter=true&width=1000&lines=Estrat√©gia+de+Qualidade)](https://git.io/typing-svg)


![Logo do git](https://www.imagensanimadas.com/data/media/1528/boneco-de-palito-imagem-animada-0041.gif)



# üìú Estrat√©gia de Qualidade

 

A qualidade de software deve estar presente em todo o desenvolvimento de software.
Ela n√£o deve ser pensada apenas como uma etapa a ser realizada ap√≥s a
codifica√ß√£o.

N√£o se resumindo apenas a testes manuais e explorat√≥rios, ela compreende a
entrega de c√≥digo bem escrito, cria√ß√£o de solu√ß√µes guiadas por testes e entrega
de c√≥digo continuamente. Em suma, a partir de boas pr√°ticas de engenharia de software
√© poss√≠vel garantir qualidade.

Entretanto, garantir qualidade √© tamb√©m ter a certeza de que as necessidades dos
usu√°rios finais s√£o atendidas e que o software em quest√£o adiciona valor ao neg√≥cio.

Pensar em estrat√©gia de qualidade compreende:

<!-- toc -->

## Tipos de testes

Para assegurar a qualidade em projetos de desenvolvimento de software, existem alguns
tipos de testes que podem ser aplicados como parte da estrat√©gia de qualidade.
Os tipos de testes podem variar conforme o contexto em quest√£o e em alguns projetos
talvez seja necess√°ria a aplica√ß√£o de mais de um tipo. Alguns exemplos de testes
mais comumente encontrados, mas n√£o se limitando aos citados abaixo, s√£o:

### Testes funcionais

Estes testes t√™m como prop√≥sito verificar *o que* o sistema faz,
bem como se atende as necessidades pr√©-determinadas para o mesmo.

Alguns testes considerados funcionais s√£o:

* **Testes manuais**: s√£o testes realizados pela equipe do projeto, que simulam a
  itera√ß√£o do usu√°rio final com o sistema em quest√£o. Deve seguir uma especifica√ß√£o
  de teste (plano de teste, caso de teste ou cen√°rio de teste) criada pela pr√≥pria
  equipe do projeto e baseada nos requisitos da aplica√ß√£o.
* **Testes automatizados de interface**: visam a automa√ß√£o de cen√°rios de testes
 a n√≠vel de tela, aonde simulam os comportamentos realizados manualmente por usu√°rios.
* **Testes automatizados de integra√ß√£o**: testam a intera√ß√£o entre sistemas e parte
  isoladas de software a fim de garantir que o conjunto se comporte da forma esperada
  quando integrados.
* **Testes explorat√≥rios**: aqui a ideia √© a mesma dos testes manuais, por√©m,
  n√£o existe uma especifica√ß√£o de teste a ser seguida.
  Geralmente testes explorat√≥rios s√£o baseados em experi√™ncia,
  uma vez que o testador deve explorar o sistema de forma a diversificar
  ao m√°ximo as op√ß√µes de uso, encontrando assim falhas n√£o identificadas nos testes
  baseados em documenta√ß√£o.
* **Testes de regress√£o**: visam garantir que outras partes do software n√£o
  tenham sido impactados por altera√ß√µes recentes.
  Tais testes podem ser manuais ou automatizados.
* **Testes de fuma√ßa**: s√£o compostos por uma pequena su√≠te de todos os testes do
  sistema em quest√£o, onde apenas as principais funcionalidades s√£o validadas.
  Tais testes podem ser manuais ou automatizados e
  geralmente s√£o executados ap√≥s uma nova vers√£o do software ser gerada.

### Testes n√£o funcionais

Estes testes t√™m como finalidade verificar *como* o sistema
se comporta mediante alguma situa√ß√£o. Alguns testes considerados n√£o funcionais s√£o:

* **Testes de performance**: s√£o testes que basicamente verificam como sua aplica√ß√£o
  se comporta em situa√ß√µes extremas, por exemplo,
  quando v√°rios usu√°rios est√£o acessando a mesma p√°gina em um curto per√≠odo de tempo.
  Esses testes tem como objetivo captar poss√≠veis pontos de gargalo no sistema.
* **Teste de seguran√ßa**: visam garantir o qu√£o seguro um sistema √©,
  expondo o mesmo a situa√ß√µes que simulam ataques que aproveitam vulnerabilidades
  espec√≠ficas, como por exemplo SQL Injection, Cross-Site Scripting e quebra de autentica√ß√£o.
* **Teste de usabilidade**: esses testes s√£o usados para compreender melhor a intera√ß√£o
  do usu√°rio com o produto.
  Geralmente √© usado como uma t√©cnica de avalia√ß√£o,
  onde existe um roteiro a ser seguido e um grupo de analistas observando e
  coletando feedbacks ou problemas, como por exemplo,
  ambiguidade de informa√ß√µes ou complica√ß√µes no fluxo do sistema.

### Recursos

* [[Artigo] Tipos de testes de software](http://testesdesoftware.com/tipos-de-teste-de-software/)
* [[Artigo] Os 13 principais tipos de testes de software](http://www.targettrust.com.br/blog/desenvolvimento/testes/os-13-principais-tipos-de-testes-de-software/)
* [[Artigo] Performance testing in a Nutshell](https://www.thoughtworks.com/insights/blog/performance-testing-nutshell)
  :uk:
* [[Artigo] Breve introdu√ß√£o a teste de performance](https://medium.com/@pedrro/uma-breve-introdu%C3%A7%C3%A3o-a-teste-de-performance-31e788337157#.f7gfk7koc)
* [[Artigo] Boas Pr√°ticas de Teste Automatizado](http://www.bugbang.com.br/agile-brazil-2012-boas-praticas-de-teste-automatizado/)
* [[Artigo] Testes Funcionais - Como decidir o que automatizar?](https://www.thoughtworks.com/pt/insights/blog/functional-tests-how-decide-what-automate)
* [[Artigo] Escreva Testes Melhores em 5 Passos](https://www.thoughtworks.com/pt/insights/blog/write-better-tests-5-steps)
* [[Livro Gratuito] Pr√°ticas e Tend√™ncias em Teste](https://info.thoughtworks.com/praticas-e-tendencias-em-teste-ebook.html)

## Pir√¢mide de testes

A pir√¢mide de testes √© um conceito proposto por Mike Cohn que tem como objetivo
guiar uma equipe de desenvolvimento para um conjunto de verifica√ß√µes eficientes,
assim permitindo que um dado produto ou solu√ß√£o evolua com seguran√ßa.

Nesse conceito, √© muito comum encontrar tr√™s n√≠veis de testes:

* No primeiro n√≠vel (base da pir√¢mide), temos os testes unit√°rios
  que devem estar presentes em maior n√∫mero por proporcionarem execu√ß√£o
  e feedback mais r√°pidos √†s pessoas que desenvolvem o software. Esses testes
  guiam o desenvolvimento e nos d√£o garantias de como o produto est√° sendo constru√≠do.

* No n√≠vel intermedi√°rio, est√£o os testes de integra√ß√£o. Estes testes
  n√£o devem estar presentes em um n√∫mero t√£o elevado quanto os testes
  unit√°rios, por serem menos eficientes com rela√ß√£o a execu√ß√£o e feedback. Aqui
  a ideia √© garantir que m√≥dulos da aplica√ß√£o funcionam em conjunto ou com algum
  colaborador externo, por exemplo um banco de dados.

* Por fim, no topo da pir√¢mide, encontramos os testes de interface automatizados
  que tendem a ser os testes onde se gasta maior investimento de tempo
  para se escrever e dar manuten√ß√£o. Al√©m disso, sua execu√ß√£o √© lenta,
  n√£o oferecendo um feedback r√°pido o suficiente para uma equipe de
  desenvolvimento √°gil. Desta forma, s√£o os testes que devem aparecer
  em menor quantidade quando comparado aos demais n√≠veis da pir√¢mide. Jornadas de
  usu√°rios e fluxos que trazem mais valor ao produto devem ser priorizados nesse
  tipo de teste.

Al√©m disso, podemos considerar que os testes presentes em qualquer pir√¢mide de teste
t√™m como objetivo dar suporte a decis√µes de desenvolvimento ou de neg√≥cio.

* Os testes da base da pir√¢mide garantem que o c√≥digo est√° correto, o foco √© a
  implementa√ß√£o da solu√ß√£o. *N√≥s estamos construindo corretamente o produto?*
* Os testes do topo da pir√¢mide garantem que a inten√ß√£o do produto est√° de acordo
  como a vis√£o dos usu√°rios e neg√≥cio. *N√≥s estamos construindo o produto correto?*

### Deriva√ß√µes da pir√¢mide de testes

√â comum encontrar em projetos algumas deriva√ß√µes da pir√¢mide de testes,
as quais s√£o advindas de uma estrat√©gia de testes por vezes equivocada.
Os principais anti-padr√µes que podemos encontrar e tentar evitar s√£o:

* A casquinha de sorvete, que na verdade trata-se de uma pir√¢mide invertida,
  pode ser observada em cen√°rios onde testes de interface automatizados e manuais
  s√£o encontrados em grande quantidade, enquanto os unit√°rios e de integra√ß√£o
  praticamente n√£o existem.

* O cupcake √© comumente encontrado em ambientes onde diferentes equipes
  s√£o respons√°veis por testes em diferentes n√≠veis. Desta forma, cada time acaba
  por tentar ter uma cobertura m√°xima em seus testes e o resultado disto
  √© o excesso de testes em todos os n√≠veis da pir√¢mide, al√©m de muita redund√¢ncia.

### Recursos

* [[Artigo] Test Pyramid](http://martinfowler.com/bliki/TestPyramid.html) :uk:
* [[Artigo] The Forgotten Layer of the Test Pyramid](https://goo.gl/vYIKPw) :uk:
* [[Artigo] Melhorando sua Estrat√©gia de Testes Automatizados](https://goo.gl/U9ddnM)
* [[Artigo] Introducing the Software Testing Cupcake (Anti-Pattern)](https://goo.gl/P9NgQN)
  :uk:

## An√°lise de C√≥digo

### An√°lise de C√≥digo com ferramentas automatizadas

A cada linha de c√≥digo escrita, provavelmente mais complexidade √© adicionada a aplica√ß√£o.
Isso torna mais dif√≠cil manter a aplica√ß√£o e assim consequentemente mais complicado
criar novas funcionalidades.
Para ajudar nesse processo existem ferramentas que analisam o c√≥digo de maneira autom√°tica.
Como por exemplo:

* [Sonarqube](http://www.sonarqube.org/)
* [Checkstyle](http://checkstyle.sourceforge.net/)
* [FindBugs](http://findbugs.sourceforge.net/)

Essas ferramentas podem identificar
pequenos problemas no c√≥digo e, geralmente, ajudam nos seguintes cen√°rios:

* Duplica√ß√µes de c√≥digo
* Coment√°rios desnecess√°rios
* Complexidade ciclom√°tica
* Cobertura de testes inexistente

### Recursos

* [[Artigo] Melhorando a qualidade do c√≥digo com sonarqube](https://goo.gl/brR0YF)

## Cobertura de Testes

Existem ferramentas que t√™m como objetivo determinar se um c√≥digo de
uma aplica√ß√£o possui ou n√£o testes.
Isso √© muito √∫til quando queremos entender o quanto do
comportamento ou inten√ß√£o da aplica√ß√£o est√° sendo validado.
Assim, consequentemente, pode-se alterar a aplica√ß√£o com maior seguran√ßa e
eventuais falhas podem ser percebidas mais rapidamente.

√â importante dizer que a maioria dessas ferramentas trabalha com testes do tipo
unit√°rio. Al√©m disso, o foco delas √© realizar uma avalia√ß√£o quantitativa, sem
focar na qualidade exata dos cen√°rios de testes existentes.
Por exemplo: √© poss√≠vel ter uma
boa cobertura de testes unit√°rios sem cobrir partes importantes da aplica√ß√£o.
Ou, ainda ter uma cobertura de testes razo√°vel,
mas que n√£o cobre cen√°rios de borda do c√≥digo.

Ent√£o, para se ter uma no√ß√£o exata e qualitativa dos testes existentes,
utilizam-se ferramentas espec√≠ficas, que alteram o c√≥digo da aplica√ß√£o e avaliam
a qualidade do testes a partir de falhas ou n√£o dos cen√°rios cobertos. Esses s√£o
os testes de muta√ß√£o.

### Recursos

* [Jacoco](http://www.eclemma.org/jacoco/)
* [Cobertura](https://github.com/cobertura/cobertura)
* [Coveralls](https://coveralls.io/)
* [Ferramenta para testes de muta√ß√£o em Java](http://pitest.org/)

## Cultura de qualidade em projetos

### Programa√ß√£o em Par

Programa√ß√£o em par √© a t√©cnica onde duas pessoas trabalham juntas no desenvolvimento
da mesma solu√ß√£o. Ter duas pessoas trabalhando ao mesmo tempo pode parecer um desperd√≠cio,
pois elas poderiam estar desenvolvendo outras atividades, mas a principal dificuldade
no desenvolvimento de software n√£o √© a quantidade de c√≥digo que √© escrito,
mas sim ter entendimento do que o c√≥digo faz e deveria fazer. Programa√ß√£o em par
otimiza o entendimento compartilhado e √© uma t√©cnica poderosa para criar uma
cultura de qualidade com a equipe. Desenvolver em pares n√£o √© uma t√©cnica
simples e requer muito alinhamento entre as pessoas, caso isso n√£o funcione pode-se
utilizar Pull Requests para garantir que outras pessoas olhem o c√≥digo que est√°
sendo desenvolvido.

### Pull request

Em alguns projetos que utilizam desenvolvimento orientado por branches,
√© comum realizar a an√°lise de c√≥digo, por meio da pr√°tica de [Pull Request](https://goo.gl/SxiPGr),
onde a cada push realizado para o reposit√≥rio √© criado um "pull request"
e outro membro da equipe se responsabiliza por revisar o c√≥digo,
com a inten√ß√£o de encontrar poss√≠veis problemas e sugerir melhorias na implementa√ß√£o.

### Kick-Off

Kick-Off √© uma pr√°tica realizada antes de uma est√≥ria come√ßar,
onde √© feita uma revis√£o com os respons√°veis pela est√≥ria,
geralmente desenvolvedores, analistas de neg√≥cios e analistas de qualidade.
Nessa revis√£o s√£o verificados quais os pontos importantes daquela est√≥ria,
deixando claro os crit√©rios de aceita√ß√£o, eventuais depend√™ncias e tamb√©m
esclarecendo quaisquer d√∫vidas que possam surgir.
A finalidade √© garantir que antes de se come√ßar a nova est√≥ria,
as pessoas envolvidas saibam o que realmente tem que ser feito.

### Desk-Check

Na pr√°tica de Desk-Check geralmente temos uma revis√£o,
do que foi desenvolvido na est√≥ria,
envolvendo as pessoas que trabalharam no desenvolvimento da mesma,
al√©m de analistas de neg√≥cio e de qualidade.
Nesta revis√£o algumas verifica√ß√µes que podem ser feitas s√£o:

* Todos os crit√©rios de aceita√ß√£o foram alcan√ßados?
* Toda a implementa√ß√£o est√° coberta por testes em seus n√≠veis?
* Ficou algum d√≠vida t√©cnica nessa est√≥ria?

### Recursos

* [[Artigo] Programa√ß√£o em Par](https://goo.gl/mRNeHn)
* [[Artigo] The benefits of pull request](https://goo.gl/s62Xjk) :uk:
* [[Artigo] Pair Programming vs. Code Reviews](https://goo.gl/duu3UW) :uk:
* [[Artigo] Defect Prevention Using Agile Techniques](https://goo.gl/sbkWr4) :uk:
